{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the data from `../datasets/real/2019-10-18/raw` and presents it in a way the model can digest. There are two types or inputs/outputs we want to be able to generate:\n",
    "\n",
    "- Motor Predictions (MP): given a starting position and a final position, how many motor ticks does it take?\n",
    "- Position Predictions (PP): given a starting position and a number of motor ticks, where will the platform end?\n",
    "\n",
    "Both problems have multiple solutions: if a cable is not tensed, there are multiple possibilities for motor control to end up in a given position. And when a starting position comprises a slack cable, it is impossible to guess the amount of ticks that are necessary to bring it back to a tensed position.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True,\n",
    "   formatter={'float_kind':'{:.2f}'.format})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State machine:\n",
    "# 0: skip everything until a \"f -1 ...\" line happens, which means a new record session is happening and the timestamps are being reset\n",
    "# 1: wait until the positions returned by \"f ...\" change. It takes me typically a few seconds to set artoolkit and to start the random sequence\n",
    "# 2: use the data\n",
    "\n",
    "def parse_file(f):\n",
    "    #print(f)\n",
    "    state = 0\n",
    "    ticks = list()\n",
    "    poses = list()\n",
    "    for l in open(f).read().split(\"\\n\"):\n",
    "        arr=l.rstrip(\" \").split(\" \")\n",
    "        if len(arr)>2:\n",
    "            if state == 0:\n",
    "                if arr[0]==\"f\" and arr[1]==\"-1\":\n",
    "                    old_ticks = \" \".join(arr[2:])\n",
    "                    state = 1\n",
    "            if state == 1:\n",
    "                if arr[0]==\"f\" and \" \".join(arr[2:]) != old_ticks:\n",
    "                    state = 2\n",
    "            if state == 2:\n",
    "                if arr[0]==\"f\":\n",
    "                    ticks.append([float(arr[1])]+[int(x) for x in arr[2:]])\n",
    "                if arr[0]==\"p\":\n",
    "                    poses.append([float(x) for x in arr[1:]])\n",
    "    return ticks, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have ticks and poses, with aligned timestamps, we can create data points which will comprise \n",
    "# two poses and a delta of ticks.\n",
    "# A few things I know from how the data is generate:\n",
    "# - it is guaranteed that each \"f\" line will have a \"p\" line with the exact same timestamp\n",
    "# - movements were generated as 3 seconds straight movements\n",
    "# - There were all kind of oscillations and imperfections in the movements so I am expecting +/- 15Â° error in the\n",
    "#   orientation and mayb +/- 5 cm in the position\n",
    "# - As a consequence, I think pairs that are a long time (and distance) apart bring more information than pairs \n",
    "#   that are close\n",
    "\n",
    "def create_training_pairs(ticks, poses):\n",
    "    # match ticks and poses of same timestamp:\n",
    "    t_ts=dict()\n",
    "    p_ts=dict()\n",
    "    for t in ticks:\n",
    "        t_ts[t[0]] = t[1:]\n",
    "    for p in poses:\n",
    "        p_ts[p[0]] = p[1:]\n",
    "    fullposes=list()\n",
    "    for ts in t_ts.keys():\n",
    "        if ts in p_ts:\n",
    "            fullposes.append([ts]+t_ts[ts]+p_ts[ts])\n",
    "            \n",
    "    # Now we make pairs of decreasing length until we arrive at 3 sec of timestamp delta\n",
    "    # Note: it is possible to generate MUCH MORE pairs from these data.\n",
    "    \n",
    "    start_ind = 0\n",
    "    end_ind = len(fullposes)-1\n",
    "    pairs=list()\n",
    "    while(fullposes[end_ind][0]-fullposes[start_ind][0]>3.0):\n",
    "        delta_ticks = [fullposes[end_ind][i]-fullposes[start_ind][i] for i in range(1,5)]\n",
    "        pairs.append(fullposes[start_ind][5:] + delta_ticks + fullposes[end_ind][5:])\n",
    "        start_ind+=1\n",
    "        end_ind-=1\n",
    "    return pairs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(arr, cols=[]):\n",
    "    norm_factors=list()\n",
    "    for c in cols:\n",
    "        v = arr[:, c]\n",
    "        offset = v.min()\n",
    "        scale = v.max() - v.min()\n",
    "        arr[:, c] = (v - v.min()) / (v.max() - v.min())\n",
    "        norm_factors.append((c, offset, scale))\n",
    "    return norm_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirname):\n",
    "    pairs = list()\n",
    "    for f in os.listdir(dirname):\n",
    "        t,p = parse_file(dirname+f)\n",
    "        pairs += create_training_pairs(t,p)\n",
    "    src_poses = np.array(pairs)[...,0:7]\n",
    "    delta_ticks = np.array(pairs)[...,7:11]\n",
    "    dst_poses = np.array(pairs)[...,11:]\n",
    "\n",
    "    # mp_ = Motors Prediction model\n",
    "    # pp_ = Position Prediction model\n",
    "\n",
    "    pp_input = np.concatenate((src_poses, delta_ticks), axis=1)\n",
    "    pp_output = np.array(dst_poses)\n",
    "\n",
    "    mp_input = np.concatenate((src_poses, dst_poses), axis=1)\n",
    "    mp_output = np.array(delta_ticks)\n",
    "    \n",
    "    normalize_columns(pp_input, [4,5,6,7,8,9,10])\n",
    "    normalize_columns(pp_output, [4,5,6])\n",
    "    normalize_columns(mp_input, [4,5,6,11,12,13])\n",
    "    normalize_columns(mp_output, [0,1,2,3])\n",
    "    \n",
    "    return(pp_input, pp_output, mp_input, mp_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.66, -0.14, -0.15, ..., 0.61, 0.51, 0.42],\n",
       "        [0.66, -0.14, -0.15, ..., 0.61, 0.52, 0.42],\n",
       "        [0.66, -0.14, -0.16, ..., 0.61, 0.52, 0.41],\n",
       "        ...,\n",
       "        [0.63, -0.29, -0.35, ..., 0.50, 0.73, 0.41],\n",
       "        [0.62, -0.28, -0.35, ..., 0.50, 0.72, 0.41],\n",
       "        [0.61, -0.29, -0.36, ..., 0.51, 0.71, 0.41]]),\n",
       " array([[0.76, -0.24, -0.11, ..., 0.34, 0.61, 0.95],\n",
       "        [0.76, -0.25, -0.11, ..., 0.33, 0.61, 0.96],\n",
       "        [0.76, -0.25, -0.11, ..., 0.33, 0.61, 0.96],\n",
       "        ...,\n",
       "        [0.61, -0.31, -0.34, ..., 0.40, 0.26, 0.12],\n",
       "        [0.60, -0.30, -0.34, ..., 0.40, 0.27, 0.12],\n",
       "        [0.61, -0.31, -0.34, ..., 0.40, 0.28, 0.13]]),\n",
       " array([[0.66, -0.14, -0.15, ..., 0.34, 0.61, 0.95],\n",
       "        [0.66, -0.14, -0.15, ..., 0.33, 0.61, 0.96],\n",
       "        [0.66, -0.14, -0.16, ..., 0.33, 0.61, 0.96],\n",
       "        ...,\n",
       "        [0.63, -0.29, -0.35, ..., 0.40, 0.26, 0.12],\n",
       "        [0.62, -0.28, -0.35, ..., 0.40, 0.27, 0.12],\n",
       "        [0.61, -0.29, -0.36, ..., 0.40, 0.28, 0.13]]),\n",
       " array([[0.35, 0.61, 0.51, 0.42],\n",
       "        [0.34, 0.61, 0.52, 0.42],\n",
       "        [0.34, 0.61, 0.52, 0.41],\n",
       "        ...,\n",
       "        [0.44, 0.50, 0.73, 0.41],\n",
       "        [0.45, 0.50, 0.72, 0.41],\n",
       "        [0.45, 0.51, 0.71, 0.41]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"../datasets/real/2019-10-18/raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, I finally understand why so many people criticize jupyter. I'll make a proper python module with all the functions in that notebook and call it fae_loader."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

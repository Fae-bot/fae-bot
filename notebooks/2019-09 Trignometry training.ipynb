{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this experiment is to try and teach non-linear functions (trigo functions, power, combinations and multiplication of these) to a DL model and see how well it fares.\n",
    "\n",
    "For the Fae bot I basically want the model to learn how to handle projections and rotation matrices. It needs to be comfortable with things like 1/(sqrt(cos(a)*sin(-b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class NBatchLogger(Callback):\n",
    "    \"\"\"\n",
    "    A Logger that log average performance per `display` steps.\n",
    "    \"\"\"\n",
    "    def __init__(self, display):\n",
    "        self.step = 0\n",
    "        self.display = display\n",
    "        self.metric_cache = {}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.step += 1\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.metric_cache[k] = self.metric_cache.get(k, 0) + logs[k]\n",
    "        if self.step % self.display == 0:\n",
    "            metrics_log = ''\n",
    "            for (k, v) in self.metric_cache.items():\n",
    "                val = v / self.display\n",
    "                if abs(val) > 1e-3:\n",
    "                    metrics_log += ' - %s: %.4f' % (k, val)\n",
    "                else:\n",
    "                    metrics_log += ' - %s: %.4e' % (k, val)\n",
    "            print('step: {}/{} ... {}'.format(self.step,\n",
    "                                          self.params['epochs'],\n",
    "                                          metrics_log))\n",
    "            self.metric_cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "# Function to be taught\n",
    "\n",
    "def secret_func(ins):\n",
    "    ca=100.0\n",
    "    cb=-87.9\n",
    "    #ca=0.0001\n",
    "    #cb=-0.000879\n",
    "    a,b,c,d,e,f=ins\n",
    "    return e*cos(sin(f))*1.0/(1.0+(cos(ca*a*d)*sin(cb*b)**2)**c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001776538427897217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_func([-1,-1,-1,0.5,.5,.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset\n",
    "\n",
    "from random import random\n",
    "\n",
    "def generate_training(sz1, sz2):\n",
    "    inputs = list()\n",
    "    outputs = list()\n",
    "    for k in range (sz2):\n",
    "        inputs.append([random() for i in range(sz1)])\n",
    "        outputs.append(secret_func(inputs[-1]))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = generate_training(6,1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08890037936393602,\n",
       " 0.35112704711024806,\n",
       " 0.4710260300137159,\n",
       " (0.2685480957558578-0.03160998337198243j),\n",
       " (0.11420017574079881-0.006117668438792973j),\n",
       " (0.3615356936675377-0.04186293083985107j),\n",
       " (0.5026345875530822-0.21350488878318405j),\n",
       " (0.36801633283352836-0.3988537848368489j),\n",
       " 0.21479619753117357,\n",
       " 0.08261121127216428]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 160)               1120      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 27,041\n",
      "Trainable params: 27,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "step: 100/4000 ...  - loss: 0.0964 - acc: 0.0000e+00\n",
      "step: 200/4000 ...  - loss: 0.0828 - acc: 0.0000e+00\n",
      "step: 300/4000 ...  - loss: 0.0826 - acc: 0.0000e+00\n",
      "step: 400/4000 ...  - loss: 0.0819 - acc: 0.0000e+00\n",
      "step: 500/4000 ...  - loss: 0.0811 - acc: 0.0000e+00\n",
      "step: 600/4000 ...  - loss: 0.0793 - acc: 0.0000e+00\n",
      "step: 700/4000 ...  - loss: 0.0781 - acc: 0.0000e+00\n",
      "step: 800/4000 ...  - loss: 0.0777 - acc: 0.0000e+00\n",
      "step: 900/4000 ...  - loss: 0.0773 - acc: 0.0000e+00\n",
      "step: 1000/4000 ...  - loss: 0.0769 - acc: 0.0000e+00\n",
      "step: 1100/4000 ...  - loss: 0.0768 - acc: 0.0000e+00\n",
      "step: 1200/4000 ...  - loss: 0.0766 - acc: 0.0000e+00\n",
      "step: 1300/4000 ...  - loss: 0.0766 - acc: 0.0000e+00\n",
      "step: 1400/4000 ...  - loss: 0.0764 - acc: 0.0000e+00\n",
      "step: 1500/4000 ...  - loss: 0.0763 - acc: 0.0000e+00\n",
      "step: 1600/4000 ...  - loss: 0.0762 - acc: 0.0000e+00\n",
      "step: 1700/4000 ...  - loss: 0.0766 - acc: 0.0000e+00\n",
      "step: 1800/4000 ...  - loss: 0.0760 - acc: 0.0000e+00\n",
      "step: 1900/4000 ...  - loss: 0.0759 - acc: 0.0000e+00\n",
      "step: 2000/4000 ...  - loss: 0.0758 - acc: 0.0000e+00\n",
      "step: 2100/4000 ...  - loss: 0.0756 - acc: 0.0000e+00\n",
      "step: 2200/4000 ...  - loss: 0.0767 - acc: 0.0000e+00\n",
      "step: 2300/4000 ...  - loss: 0.0755 - acc: 0.0000e+00\n",
      "step: 2400/4000 ...  - loss: 0.0753 - acc: 0.0000e+00\n",
      "step: 2500/4000 ...  - loss: 0.0752 - acc: 0.0000e+00\n",
      "step: 2600/4000 ...  - loss: 0.0750 - acc: 0.0000e+00\n",
      "step: 2700/4000 ...  - loss: 0.0749 - acc: 0.0000e+00\n",
      "step: 2800/4000 ...  - loss: 0.0756 - acc: 0.0000e+00\n",
      "step: 2900/4000 ...  - loss: 0.0754 - acc: 0.0000e+00\n",
      "step: 3000/4000 ...  - loss: 0.0745 - acc: 0.0000e+00\n",
      "step: 3100/4000 ...  - loss: 0.0743 - acc: 0.0000e+00\n",
      "step: 3200/4000 ...  - loss: 0.0740 - acc: 0.0000e+00\n",
      "step: 3300/4000 ...  - loss: 0.0736 - acc: 0.0000e+00\n",
      "step: 3400/4000 ...  - loss: 0.0758 - acc: 0.0000e+00\n",
      "step: 3500/4000 ...  - loss: 0.0730 - acc: 0.0000e+00\n",
      "step: 3600/4000 ...  - loss: 0.0723 - acc: 0.0000e+00\n",
      "step: 3700/4000 ...  - loss: 0.0715 - acc: 0.0000e+00\n",
      "step: 3800/4000 ...  - loss: 0.0704 - acc: 0.0000e+00\n",
      "step: 3900/4000 ...  - loss: 0.0731 - acc: 0.0000e+00\n",
      "step: 4000/4000 ...  - loss: 0.0687 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f21e28b7f60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(160, activation='tanh', input_shape=(6,), use_bias=True))\n",
    "model.add(Dense(160, activation='tanh', use_bias=True))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()\n",
    "#opt = SGD(lr=0.08, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "opt = Adam(lr=0.004, amsgrad=True)\n",
    "model.compile(loss='mean_squared_error',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "model.fit(inputs, outputs,\n",
    "    batch_size=10000,\n",
    "    epochs=4000,\n",
    "    verbose=0,\n",
    "    shuffle=True,\n",
    "    validation_split=0.0,\n",
    "    callbacks=[NBatchLogger(display=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e616116b2f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m535\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "ind=535\n",
    "print(model.predict(np.array([inputs[ind]]))[0])\n",
    "print(outputs[ind])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion 1\n",
    "\n",
    "The problem is not in the functions used as I first suspected. It seems to be from teh huge size of some constants (`ca` and `cb` in the `secret_func`). If I put them in the 0..1 range it works fine, but getting closer to 100 makes thr training much harder, or even impossible.\n",
    "\n",
    "Same if the constants are too small (e.g. <0.0001)\n",
    "\n",
    "### New problem\n",
    "\n",
    "Let's isolate that problem and find a model that solves it well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "# Function to be taught\n",
    "\n",
    "def secret_func(ins):\n",
    "    mult = 100.0\n",
    "    ca=1.1 * mult\n",
    "    cb=-0.879 * mult\n",
    "    a,b=ins\n",
    "    return cos(ca*a+cb*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = generate_training(2,1000) \n",
    "for i in range(len(inputs)):\n",
    "    inputs[i].append(1.0)\n",
    "    inputs[i].append(10)\n",
    "    inputs[i].append(100)\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 160)          960         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 160)          960         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 160)          0           dense_34[0][0]                   \n",
      "                                                                 dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 160)          960         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 160)          0           dense_36[0][0]                   \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 160)          960         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 160)          0           dense_37[0][0]                   \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 160)          960         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 160)          0           dense_38[0][0]                   \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 160)          640         multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 160)          640         multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 160)          640         multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 160)          640         multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 645)          0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 160)          103360      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 160)          640         dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 160)          25760       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 160)          25760       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 160)          25760       dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1)            161         dense_42[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 188,801\n",
      "Trainable params: 187,201\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = keras.layers.Input(shape=(5,))\n",
    "dense1_1 = keras.layers.Dense(160, use_bias=True, activation='relu')(input1)\n",
    "dense1_2 = keras.layers.Dense(160, use_bias=True, activation='relu')(input1)\n",
    "mult1 = keras.layers.Multiply()([dense1_1, dense1_2])\n",
    "bn1 = keras.layers.BatchNormalization()(mult1)\n",
    "    \n",
    "dense2 = keras.layers.Dense(160, use_bias=True, activation='relu')(input1)\n",
    "mult2 = keras.layers.Multiply()([dense2, mult1])\n",
    "bn2 = keras.layers.BatchNormalization()(mult2)\n",
    "\n",
    "dense3 = keras.layers.Dense(160, use_bias=True, activation='relu')(input1)\n",
    "mult3 = keras.layers.Multiply()([dense3, mult2])\n",
    "bn3 = keras.layers.BatchNormalization()(mult3)\n",
    "\n",
    "dense4 = keras.layers.Dense(160, use_bias=True, activation='relu')(input1)\n",
    "mult4 = keras.layers.Multiply()([dense4, mult3])\n",
    "bn4 = keras.layers.BatchNormalization()(mult4)\n",
    "\n",
    "merge_1 = keras.layers.Concatenate()([bn1, bn2, bn3, bn4, input1])\n",
    "\n",
    "dense2 = keras.layers.Dense(160, use_bias=True, activation='relu')(merge_1)\n",
    "bn5 = keras.layers.BatchNormalization()(dense2)\n",
    "dense3 = keras.layers.Dense(160, use_bias=True, activation='relu')(bn5)\n",
    "dense4 = keras.layers.Dense(160, use_bias=True, activation='relu')(dense3)\n",
    "dense5 = keras.layers.Dense(160, use_bias=True, activation='relu')(dense4)\n",
    "dense6 = keras.layers.Dense(160, use_bias=True, activation='relu')(dense5)\n",
    "\n",
    "out = keras.layers.Dense(1, activation='linear')(dense5)\n",
    "model = keras.models.Model(inputs=[input1], outputs=out)\n",
    "\n",
    "\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Dense(160, activation='tanh', input_shape=(6,), use_bias=True))\n",
    "#model.add(Dense(160, activation='tanh', use_bias=True))\n",
    "#model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()\n",
    "#opt = SGD(lr=0.08, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "opt = Adam(lr=0.004, amsgrad=True)\n",
    "model.compile(loss='mean_squared_error',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100/10000 ...  - loss: 0.5203 - acc: 0.0000e+00\n",
      "step: 200/10000 ...  - loss: 0.4665 - acc: 0.0000e+00\n",
      "step: 300/10000 ...  - loss: 0.4545 - acc: 0.0000e+00\n",
      "step: 400/10000 ...  - loss: 0.4219 - acc: 0.0000e+00\n",
      "step: 500/10000 ...  - loss: 0.3970 - acc: 0.0000e+00\n",
      "step: 600/10000 ...  - loss: 0.3810 - acc: 0.0000e+00\n",
      "step: 700/10000 ...  - loss: 0.3540 - acc: 0.0000e+00\n",
      "step: 800/10000 ...  - loss: 0.3532 - acc: 0.0000e+00\n",
      "step: 900/10000 ...  - loss: 0.3287 - acc: 0.0000e+00\n",
      "step: 1000/10000 ...  - loss: 0.3089 - acc: 0.0000e+00\n",
      "step: 1100/10000 ...  - loss: 0.2870 - acc: 0.0000e+00\n",
      "step: 1200/10000 ...  - loss: 0.2805 - acc: 0.0000e+00\n",
      "step: 1300/10000 ...  - loss: 0.2679 - acc: 0.0000e+00\n",
      "step: 1400/10000 ...  - loss: 0.2458 - acc: 0.0000e+00\n",
      "step: 1500/10000 ...  - loss: 0.2273 - acc: 0.0000e+00\n",
      "step: 1600/10000 ...  - loss: 0.2276 - acc: 0.0000e+00\n",
      "step: 1700/10000 ...  - loss: 0.2177 - acc: 0.0000e+00\n",
      "step: 1800/10000 ...  - loss: 0.2034 - acc: 0.0000e+00\n",
      "step: 1900/10000 ...  - loss: 0.1796 - acc: 0.0000e+00\n",
      "step: 2000/10000 ...  - loss: 0.1821 - acc: 0.0000e+00\n",
      "step: 2100/10000 ...  - loss: 0.1574 - acc: 0.0000e+00\n",
      "step: 2200/10000 ...  - loss: 0.1703 - acc: 0.0000e+00\n",
      "step: 2300/10000 ...  - loss: 0.1675 - acc: 0.0000e+00\n",
      "step: 2400/10000 ...  - loss: 0.1971 - acc: 0.0000e+00\n",
      "step: 2500/10000 ...  - loss: 0.1579 - acc: 0.0000e+00\n",
      "step: 2600/10000 ...  - loss: 0.1528 - acc: 0.0000e+00\n",
      "step: 2700/10000 ...  - loss: 0.1215 - acc: 0.0000e+00\n",
      "step: 2800/10000 ...  - loss: 0.1324 - acc: 0.0000e+00\n",
      "step: 2900/10000 ...  - loss: 0.1374 - acc: 0.0000e+00\n",
      "step: 3000/10000 ...  - loss: 0.1000 - acc: 0.0000e+00\n",
      "step: 3100/10000 ...  - loss: 0.1308 - acc: 0.0000e+00\n",
      "step: 3200/10000 ...  - loss: 0.1019 - acc: 0.0000e+00\n",
      "step: 3300/10000 ...  - loss: 0.0849 - acc: 0.0000e+00\n",
      "step: 3400/10000 ...  - loss: 0.0928 - acc: 0.0000e+00\n",
      "step: 3500/10000 ...  - loss: 0.1006 - acc: 0.0000e+00\n",
      "step: 3600/10000 ...  - loss: 0.0777 - acc: 0.0000e+00\n",
      "step: 3700/10000 ...  - loss: 0.0778 - acc: 0.0000e+00\n",
      "step: 3800/10000 ...  - loss: 0.0788 - acc: 0.0000e+00\n",
      "step: 3900/10000 ...  - loss: 0.0764 - acc: 0.0000e+00\n",
      "step: 4000/10000 ...  - loss: 0.0646 - acc: 0.0000e+00\n",
      "step: 4100/10000 ...  - loss: 0.0860 - acc: 0.0000e+00\n",
      "step: 4200/10000 ...  - loss: 0.0685 - acc: 0.0000e+00\n",
      "step: 4300/10000 ...  - loss: 0.0824 - acc: 0.0000e+00\n",
      "step: 4400/10000 ...  - loss: 0.0573 - acc: 0.0000e+00\n",
      "step: 4500/10000 ...  - loss: 0.0684 - acc: 0.0000e+00\n",
      "step: 4600/10000 ...  - loss: 0.0573 - acc: 0.0000e+00\n",
      "step: 4700/10000 ...  - loss: 0.0611 - acc: 0.0000e+00\n",
      "step: 4800/10000 ...  - loss: 0.0782 - acc: 0.0000e+00\n",
      "step: 4900/10000 ...  - loss: 0.0515 - acc: 0.0000e+00\n",
      "step: 5000/10000 ...  - loss: 0.0480 - acc: 0.0000e+00\n",
      "step: 5100/10000 ...  - loss: 0.0525 - acc: 0.0000e+00\n",
      "step: 5200/10000 ...  - loss: 0.0950 - acc: 0.0000e+00\n",
      "step: 5300/10000 ...  - loss: 0.0393 - acc: 0.0000e+00\n",
      "step: 5400/10000 ...  - loss: 0.0438 - acc: 0.0000e+00\n",
      "step: 5500/10000 ...  - loss: 0.0478 - acc: 0.0000e+00\n",
      "step: 5600/10000 ...  - loss: 0.0436 - acc: 0.0000e+00\n",
      "step: 5700/10000 ...  - loss: 0.0453 - acc: 0.0000e+00\n",
      "step: 5800/10000 ...  - loss: 0.0497 - acc: 0.0000e+00\n",
      "step: 5900/10000 ...  - loss: 0.0384 - acc: 0.0000e+00\n",
      "step: 6000/10000 ...  - loss: 0.0405 - acc: 0.0000e+00\n",
      "step: 6100/10000 ...  - loss: 0.0382 - acc: 0.0000e+00\n",
      "step: 6200/10000 ...  - loss: 0.0410 - acc: 0.0000e+00\n",
      "step: 6300/10000 ...  - loss: 0.0322 - acc: 0.0000e+00\n",
      "step: 6400/10000 ...  - loss: 0.0375 - acc: 0.0000e+00\n",
      "step: 6500/10000 ...  - loss: 0.0437 - acc: 0.0000e+00\n",
      "step: 6600/10000 ...  - loss: 0.0309 - acc: 0.0000e+00\n",
      "step: 6700/10000 ...  - loss: 0.0423 - acc: 0.0000e+00\n",
      "step: 6800/10000 ...  - loss: 0.0280 - acc: 0.0000e+00\n",
      "step: 6900/10000 ...  - loss: 0.0332 - acc: 0.0000e+00\n",
      "step: 7000/10000 ...  - loss: 0.0315 - acc: 0.0000e+00\n",
      "step: 7100/10000 ...  - loss: 0.0419 - acc: 0.0000e+00\n",
      "step: 7200/10000 ...  - loss: 0.0256 - acc: 0.0000e+00\n",
      "step: 7300/10000 ...  - loss: 0.0249 - acc: 0.0000e+00\n",
      "step: 7400/10000 ...  - loss: 0.0310 - acc: 0.0000e+00\n",
      "step: 7500/10000 ...  - loss: 0.0289 - acc: 0.0000e+00\n",
      "step: 7600/10000 ...  - loss: 0.0253 - acc: 0.0000e+00\n",
      "step: 7700/10000 ...  - loss: 0.0321 - acc: 0.0000e+00\n",
      "step: 7800/10000 ...  - loss: 0.0237 - acc: 0.0000e+00\n",
      "step: 7900/10000 ...  - loss: 0.0227 - acc: 0.0000e+00\n",
      "step: 8000/10000 ...  - loss: 0.0291 - acc: 0.0000e+00\n",
      "step: 8100/10000 ...  - loss: 0.0266 - acc: 0.0000e+00\n",
      "step: 8200/10000 ...  - loss: 0.0201 - acc: 0.0000e+00\n",
      "step: 8300/10000 ...  - loss: 0.0208 - acc: 0.0000e+00\n",
      "step: 8400/10000 ...  - loss: 0.0213 - acc: 0.0000e+00\n",
      "step: 8500/10000 ...  - loss: 0.0274 - acc: 0.0000e+00\n",
      "step: 8600/10000 ...  - loss: 0.0275 - acc: 0.0000e+00\n",
      "step: 8700/10000 ...  - loss: 0.0147 - acc: 0.0000e+00\n",
      "step: 8800/10000 ...  - loss: 0.0230 - acc: 0.0000e+00\n",
      "step: 8900/10000 ...  - loss: 0.0191 - acc: 0.0000e+00\n",
      "step: 9000/10000 ...  - loss: 0.0154 - acc: 0.0000e+00\n",
      "step: 9100/10000 ...  - loss: 0.0215 - acc: 0.0000e+00\n",
      "step: 9200/10000 ...  - loss: 0.0182 - acc: 0.0000e+00\n",
      "step: 9300/10000 ...  - loss: 0.0168 - acc: 0.0000e+00\n",
      "step: 9400/10000 ...  - loss: 0.0206 - acc: 0.0000e+00\n",
      "step: 9500/10000 ...  - loss: 0.0129 - acc: 0.0000e+00\n",
      "step: 9600/10000 ...  - loss: 0.0186 - acc: 0.0000e+00\n",
      "step: 9700/10000 ...  - loss: 0.0150 - acc: 0.0000e+00\n",
      "step: 9800/10000 ...  - loss: 0.0253 - acc: 0.0000e+00\n",
      "step: 9900/10000 ...  - loss: 0.0124 - acc: 0.0000e+00\n",
      "step: 10000/10000 ...  - loss: 0.0150 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cd471bc50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs,\n",
    "    batch_size=1000,\n",
    "    epochs=10000,\n",
    "    verbose=0,\n",
    "    shuffle=True,\n",
    "    validation_split=0.0,\n",
    "    callbacks=[NBatchLogger(display=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3501999]\n",
      "-0.3890039461518654\n"
     ]
    }
   ],
   "source": [
    "ins=inputs[0]\n",
    "ins[0] = random.random()\n",
    "ins[1] = random.random()\n",
    "print(model.predict(np.array([ins]))[0])\n",
    "print(secret_func(ins[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.130393]\n",
      "-0.6717672509600036\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ind=random.randint(0,1000)\n",
    "ins=inputs[ind]\n",
    "print(model.predict(np.array([ins]))[0])\n",
    "print(secret_func(ins[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
